# Main Job
- [x] read Prompting elicits reasoning in LLM

# What Have been Learnt
- Chain of Thoughts (CoT) improves the LLM for giving out a few-shot prompts that encourages the model to decompose the rationales thus getting the correct answers.
- Only works significantly on Huge scale models (over 100B params)

# Questions


# Interesting Things to be Reminded



[^1]:footnote here.
